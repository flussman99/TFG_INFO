{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       price         fecha\n",
      "0     27.181  Apr 01, 2014\n",
      "1     26.962  Apr 02, 2014\n",
      "2     27.305  Apr 03, 2014\n",
      "3     27.775  Apr 04, 2014\n",
      "4     27.651  Apr 07, 2014\n",
      "...      ...           ...\n",
      "2556  40.040  Mar 27, 2024\n",
      "2557  38.780  Mar 28, 2024\n",
      "2558  38.480  Apr 02, 2024\n",
      "2559  38.720  Apr 03, 2024\n",
      "2560  38.240  Apr 04, 2024\n",
      "\n",
      "[2561 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "api_key = \"2937e2b78f1093a52d383bda8dd05f928b49d4aa\"\n",
    "\n",
    "url = \"https://api.scraperlink.com/investpy/\"\n",
    "params = {\n",
    "    \"email\": \"tfginfotrading@gmail.com\",\n",
    "    \"type\": \"historical_data\",\n",
    "    \"product\": \"stocks\",\n",
    "    \"country\": \"spain\",\n",
    "    \"symbol\": \"ACS\",\n",
    "    \"from_date\": \"04/01/2014\",\n",
    "    \"to_date\": \"04/04/2024\"\n",
    "}\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_key}\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, params=params, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    # Hacer algo con los datos devueltos por la API\n",
    "    # print(data)\n",
    "    # Crear un DataFrame con los datos obtenidos\n",
    "    df = pd.DataFrame(data['data'])  # Suponiendo que 'data' es la clave que contiene los datos relevantes\n",
    "    # Reverse the order of the rows in the DataFrame\n",
    "    df = df.iloc[::-1]\n",
    "    # Reset the index of the DataFrame to start from 0\n",
    "    df = df.reset_index(drop=True)\n",
    "    # Renombrar las columnas a 'price' y 'fecha'\n",
    "    df = df.rename(columns={'last_close': 'price', 'rowDate': 'fecha'})\n",
    "\n",
    "    # Crear una nueva vista del DataFrame con solo las columnas 'price' y 'fecha'\n",
    "    df_vista = df[['price', 'fecha']]\n",
    "    # Imprimir el DataFrame resultante\n",
    "    print(df_vista)\n",
    "    # Export the DataFrame to an Excel file\n",
    "    df_vista.to_excel('output.xlsx', index=False)\n",
    "else:\n",
    "    print(f\"Error al obtener datos: {response.status_code}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       price         fecha\n",
      "0     27.181  Apr 01, 2014\n",
      "1     26.962  Apr 02, 2014\n",
      "2     27.305  Apr 03, 2014\n",
      "3     27.775  Apr 04, 2014\n",
      "4     27.651  Apr 07, 2014\n",
      "...      ...           ...\n",
      "2556  40.040  Mar 27, 2024\n",
      "2557  38.780  Mar 28, 2024\n",
      "2558  38.480  Apr 02, 2024\n",
      "2559  38.720  Apr 03, 2024\n",
      "2560  38.370  Apr 04, 2024\n",
      "\n",
      "[2561 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'pandas' has no attribute '_pandas_datetime_CAPI' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#SOLO LOS PARTIDOS DE LIGA\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbs4\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BeautifulSoup\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Lista de archivos HTML a procesar\u001b[39;00m\n\u001b[0;32m      8\u001b[0m html_files \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml/2014-2015.html\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml/2015-2016.html\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml/2022-2023.html\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     18\u001b[0m ]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\__init__.py:62\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig_init\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;66;03m# dtype\u001b[39;00m\n\u001b[0;32m     64\u001b[0m     ArrowDtype,\n\u001b[0;32m     65\u001b[0m     Int8Dtype,\n\u001b[0;32m     66\u001b[0m     Int16Dtype,\n\u001b[0;32m     67\u001b[0m     Int32Dtype,\n\u001b[0;32m     68\u001b[0m     Int64Dtype,\n\u001b[0;32m     69\u001b[0m     UInt8Dtype,\n\u001b[0;32m     70\u001b[0m     UInt16Dtype,\n\u001b[0;32m     71\u001b[0m     UInt32Dtype,\n\u001b[0;32m     72\u001b[0m     UInt64Dtype,\n\u001b[0;32m     73\u001b[0m     Float32Dtype,\n\u001b[0;32m     74\u001b[0m     Float64Dtype,\n\u001b[0;32m     75\u001b[0m     CategoricalDtype,\n\u001b[0;32m     76\u001b[0m     PeriodDtype,\n\u001b[0;32m     77\u001b[0m     IntervalDtype,\n\u001b[0;32m     78\u001b[0m     DatetimeTZDtype,\n\u001b[0;32m     79\u001b[0m     StringDtype,\n\u001b[0;32m     80\u001b[0m     BooleanDtype,\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;66;03m# missing\u001b[39;00m\n\u001b[0;32m     82\u001b[0m     NA,\n\u001b[0;32m     83\u001b[0m     isna,\n\u001b[0;32m     84\u001b[0m     isnull,\n\u001b[0;32m     85\u001b[0m     notna,\n\u001b[0;32m     86\u001b[0m     notnull,\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;66;03m# indexes\u001b[39;00m\n\u001b[0;32m     88\u001b[0m     Index,\n\u001b[0;32m     89\u001b[0m     CategoricalIndex,\n\u001b[0;32m     90\u001b[0m     RangeIndex,\n\u001b[0;32m     91\u001b[0m     MultiIndex,\n\u001b[0;32m     92\u001b[0m     IntervalIndex,\n\u001b[0;32m     93\u001b[0m     TimedeltaIndex,\n\u001b[0;32m     94\u001b[0m     DatetimeIndex,\n\u001b[0;32m     95\u001b[0m     PeriodIndex,\n\u001b[0;32m     96\u001b[0m     IndexSlice,\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;66;03m# tseries\u001b[39;00m\n\u001b[0;32m     98\u001b[0m     NaT,\n\u001b[0;32m     99\u001b[0m     Period,\n\u001b[0;32m    100\u001b[0m     period_range,\n\u001b[0;32m    101\u001b[0m     Timedelta,\n\u001b[0;32m    102\u001b[0m     timedelta_range,\n\u001b[0;32m    103\u001b[0m     Timestamp,\n\u001b[0;32m    104\u001b[0m     date_range,\n\u001b[0;32m    105\u001b[0m     bdate_range,\n\u001b[0;32m    106\u001b[0m     Interval,\n\u001b[0;32m    107\u001b[0m     interval_range,\n\u001b[0;32m    108\u001b[0m     DateOffset,\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;66;03m# conversion\u001b[39;00m\n\u001b[0;32m    110\u001b[0m     to_numeric,\n\u001b[0;32m    111\u001b[0m     to_datetime,\n\u001b[0;32m    112\u001b[0m     to_timedelta,\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;66;03m# misc\u001b[39;00m\n\u001b[0;32m    114\u001b[0m     Flags,\n\u001b[0;32m    115\u001b[0m     Grouper,\n\u001b[0;32m    116\u001b[0m     factorize,\n\u001b[0;32m    117\u001b[0m     unique,\n\u001b[0;32m    118\u001b[0m     value_counts,\n\u001b[0;32m    119\u001b[0m     NamedAgg,\n\u001b[0;32m    120\u001b[0m     array,\n\u001b[0;32m    121\u001b[0m     Categorical,\n\u001b[0;32m    122\u001b[0m     set_eng_float_format,\n\u001b[0;32m    123\u001b[0m     Series,\n\u001b[0;32m    124\u001b[0m     DataFrame,\n\u001b[0;32m    125\u001b[0m )\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtseries\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m infer_freq\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\api.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     NaT,\n\u001b[0;32m      3\u001b[0m     Period,\n\u001b[0;32m      4\u001b[0m     Timedelta,\n\u001b[0;32m      5\u001b[0m     Timestamp,\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmissing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NA\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     ArrowDtype,\n\u001b[0;32m     11\u001b[0m     CategoricalDtype,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     PeriodDtype,\n\u001b[0;32m     15\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\_libs\\__init__.py:18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_parser\u001b[39;00m  \u001b[38;5;66;03m# isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_datetime\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401 # isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     20\u001b[0m     NaT,\n\u001b[0;32m     21\u001b[0m     NaTType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     iNaT,\n\u001b[0;32m     27\u001b[0m )\n",
      "File \u001b[1;32minterval.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.interval\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mhashtable.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.hashtable\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mmissing.pyx:42\u001b[0m, in \u001b[0;36minit pandas._libs.missing\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: partially initialized module 'pandas' has no attribute '_pandas_datetime_CAPI' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "#SOLO LOS PARTIDOS DE LIGA\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Lista de archivos HTML a procesar\n",
    "html_files = [\n",
    "    'html/2014-2015.html',\n",
    "    'html/2015-2016.html',\n",
    "    'html/2016-2017.html',\n",
    "    'html/2017-2018.html',\n",
    "    'html/2018-2019.html',\n",
    "    'html/2019-2020.html',\n",
    "    'html/2020-2021.html',\n",
    "    'html/2021-2022.html',\n",
    "    'html/2022-2023.html'\n",
    "]\n",
    "\n",
    "# Lista para almacenar los datos de todos los archivos\n",
    "data = []\n",
    "\n",
    "for file_name in html_files:\n",
    "    with open(file_name, 'r', encoding='utf-8') as file:\n",
    "        html_content = file.read()\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        matches = soup.find_all('a', class_='match-link', attrs={'data-cy': 'match'})\n",
    "        \n",
    "        for match in matches:\n",
    "            competition_elem = match.find('div', class_='middle-info')\n",
    "            if competition_elem and 'Primera División' in competition_elem.get_text(strip=True):\n",
    "                date_elem = match.find('div', class_='date-transform')\n",
    "                home_team_elem = match.find('div', class_='team-name', itemprop='name')\n",
    "                away_team_elems = match.find_all('div', class_='team-name', itemprop='name')\n",
    "                result_elem = match.find('div', class_='marker')\n",
    "                \n",
    "                if date_elem and home_team_elem and len(away_team_elems) > 1 and result_elem:\n",
    "                    result_spans = result_elem.find_all('span')\n",
    "                    if len(result_spans) == 3:  # Ensure there are two result spans and one dash\n",
    "                        result_local = result_spans[1].text.strip()\n",
    "                        result_visitante = result_spans[2].text.strip()\n",
    "                        data.append([\n",
    "                            date_elem.text.strip(),\n",
    "                            competition_elem.text.strip(),\n",
    "                            home_team_elem.text.strip(),\n",
    "                            away_team_elems[1].text.strip(),\n",
    "                            result_elem.text.strip(),\n",
    "                            result_local,\n",
    "                            result_visitante\n",
    "                        ])\n",
    "\n",
    "# Crear un DataFrame con los datos combinados\n",
    "df = pd.DataFrame(data, columns=['Fecha', 'Competición', 'Equipo Local', 'Equipo Visitante','Resultado', 'ResultadoLocal', 'ResultadoVisitante'])\n",
    "\n",
    "# Después de crear el DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    if row['Equipo Local'] == 'Real Madrid':\n",
    "        if int(row['ResultadoLocal']) > int(row['ResultadoVisitante']):\n",
    "            df.loc[index, 'Decision'] = 'Ganado'\n",
    "        elif int(row['ResultadoLocal']) < int(row['ResultadoVisitante']):\n",
    "            df.loc[index, 'Decision'] = 'Perdido'\n",
    "        else:\n",
    "            df.loc[index, 'Decision'] = 'Empatado'\n",
    "    else:\n",
    "        if int(row['ResultadoVisitante']) > int(row['ResultadoLocal']):\n",
    "            df.loc[index, 'Decision'] = 'Ganado'\n",
    "        elif int(row['ResultadoLocal']) > int(row['ResultadoVisitante']):\n",
    "            df.loc[index, 'Decision'] = 'Perdido'\n",
    "        else:\n",
    "            df.loc[index, 'Decision'] = 'Empatado'\n",
    "\n",
    "\n",
    "\n",
    "# Guardar los datos en un archivo Excel\n",
    "df.to_excel('real_madrid_primera_division_matches_combined.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'pandas' has no attribute '_pandas_datetime_CAPI' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#En directo de la url\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbs4\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BeautifulSoup\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\__init__.py:62\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig_init\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;66;03m# dtype\u001b[39;00m\n\u001b[0;32m     64\u001b[0m     ArrowDtype,\n\u001b[0;32m     65\u001b[0m     Int8Dtype,\n\u001b[0;32m     66\u001b[0m     Int16Dtype,\n\u001b[0;32m     67\u001b[0m     Int32Dtype,\n\u001b[0;32m     68\u001b[0m     Int64Dtype,\n\u001b[0;32m     69\u001b[0m     UInt8Dtype,\n\u001b[0;32m     70\u001b[0m     UInt16Dtype,\n\u001b[0;32m     71\u001b[0m     UInt32Dtype,\n\u001b[0;32m     72\u001b[0m     UInt64Dtype,\n\u001b[0;32m     73\u001b[0m     Float32Dtype,\n\u001b[0;32m     74\u001b[0m     Float64Dtype,\n\u001b[0;32m     75\u001b[0m     CategoricalDtype,\n\u001b[0;32m     76\u001b[0m     PeriodDtype,\n\u001b[0;32m     77\u001b[0m     IntervalDtype,\n\u001b[0;32m     78\u001b[0m     DatetimeTZDtype,\n\u001b[0;32m     79\u001b[0m     StringDtype,\n\u001b[0;32m     80\u001b[0m     BooleanDtype,\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;66;03m# missing\u001b[39;00m\n\u001b[0;32m     82\u001b[0m     NA,\n\u001b[0;32m     83\u001b[0m     isna,\n\u001b[0;32m     84\u001b[0m     isnull,\n\u001b[0;32m     85\u001b[0m     notna,\n\u001b[0;32m     86\u001b[0m     notnull,\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;66;03m# indexes\u001b[39;00m\n\u001b[0;32m     88\u001b[0m     Index,\n\u001b[0;32m     89\u001b[0m     CategoricalIndex,\n\u001b[0;32m     90\u001b[0m     RangeIndex,\n\u001b[0;32m     91\u001b[0m     MultiIndex,\n\u001b[0;32m     92\u001b[0m     IntervalIndex,\n\u001b[0;32m     93\u001b[0m     TimedeltaIndex,\n\u001b[0;32m     94\u001b[0m     DatetimeIndex,\n\u001b[0;32m     95\u001b[0m     PeriodIndex,\n\u001b[0;32m     96\u001b[0m     IndexSlice,\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;66;03m# tseries\u001b[39;00m\n\u001b[0;32m     98\u001b[0m     NaT,\n\u001b[0;32m     99\u001b[0m     Period,\n\u001b[0;32m    100\u001b[0m     period_range,\n\u001b[0;32m    101\u001b[0m     Timedelta,\n\u001b[0;32m    102\u001b[0m     timedelta_range,\n\u001b[0;32m    103\u001b[0m     Timestamp,\n\u001b[0;32m    104\u001b[0m     date_range,\n\u001b[0;32m    105\u001b[0m     bdate_range,\n\u001b[0;32m    106\u001b[0m     Interval,\n\u001b[0;32m    107\u001b[0m     interval_range,\n\u001b[0;32m    108\u001b[0m     DateOffset,\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;66;03m# conversion\u001b[39;00m\n\u001b[0;32m    110\u001b[0m     to_numeric,\n\u001b[0;32m    111\u001b[0m     to_datetime,\n\u001b[0;32m    112\u001b[0m     to_timedelta,\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;66;03m# misc\u001b[39;00m\n\u001b[0;32m    114\u001b[0m     Flags,\n\u001b[0;32m    115\u001b[0m     Grouper,\n\u001b[0;32m    116\u001b[0m     factorize,\n\u001b[0;32m    117\u001b[0m     unique,\n\u001b[0;32m    118\u001b[0m     value_counts,\n\u001b[0;32m    119\u001b[0m     NamedAgg,\n\u001b[0;32m    120\u001b[0m     array,\n\u001b[0;32m    121\u001b[0m     Categorical,\n\u001b[0;32m    122\u001b[0m     set_eng_float_format,\n\u001b[0;32m    123\u001b[0m     Series,\n\u001b[0;32m    124\u001b[0m     DataFrame,\n\u001b[0;32m    125\u001b[0m )\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtseries\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m infer_freq\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\api.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     NaT,\n\u001b[0;32m      3\u001b[0m     Period,\n\u001b[0;32m      4\u001b[0m     Timedelta,\n\u001b[0;32m      5\u001b[0m     Timestamp,\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmissing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NA\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     ArrowDtype,\n\u001b[0;32m     11\u001b[0m     CategoricalDtype,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     PeriodDtype,\n\u001b[0;32m     15\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\_libs\\__init__.py:18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_parser\u001b[39;00m  \u001b[38;5;66;03m# isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_datetime\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401 # isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     20\u001b[0m     NaT,\n\u001b[0;32m     21\u001b[0m     NaTType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     iNaT,\n\u001b[0;32m     27\u001b[0m )\n",
      "File \u001b[1;32minterval.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.interval\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mhashtable.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.hashtable\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mmissing.pyx:42\u001b[0m, in \u001b[0;36minit pandas._libs.missing\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: partially initialized module 'pandas' has no attribute '_pandas_datetime_CAPI' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "#En directo de la url\n",
    "\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import requests\n",
    "\n",
    "url = \"https://es.besoccer.com/equipo/partidos/real-madrid\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Lista para almacenar los datos de todos los archivos\n",
    "data = []\n",
    "\n",
    "if response.status_code == 200:\n",
    "    respuesta = response.text\n",
    "    soup = BeautifulSoup(respuesta, 'html.parser')\n",
    "    matches = soup.find_all('a', class_='match-link', attrs={'data-cy': 'match'})\n",
    "\n",
    "        \n",
    "    for match in matches:\n",
    "            competition_elem = match.find('div', class_='middle-info')\n",
    "            if competition_elem and 'Primera División' in competition_elem.get_text(strip=True):\n",
    "                date_elem = match.find('div', class_='date-transform')\n",
    "                home_team_elem = match.find('div', class_='team-name', itemprop='name')\n",
    "                away_team_elems = match.find_all('div', class_='team-name', itemprop='name')\n",
    "                result_elem = match.find('div', class_='marker')\n",
    "                \n",
    "                if date_elem and home_team_elem and len(away_team_elems) > 1 and result_elem:\n",
    "                    result_spans = result_elem.find_all('span')\n",
    "                    if len(result_spans) == 3:  # Ensure there are two result spans and one dash\n",
    "                        result_local = result_spans[1].text.strip()\n",
    "                        result_visitante = result_spans[2].text.strip()\n",
    "                        data.append([\n",
    "                            date_elem.text.strip(),\n",
    "                            competition_elem.text.strip(),\n",
    "                            home_team_elem.text.strip(),\n",
    "                            away_team_elems[1].text.strip(),\n",
    "                            result_elem.text.strip(),\n",
    "                            result_local,\n",
    "                            result_visitante\n",
    "                        ])\n",
    "\n",
    "# Crear un DataFrame con los datos combinados\n",
    "    df = pd.DataFrame(data, columns=['Fecha', 'Competición', 'Equipo Local', 'Equipo Visitante','Resultado', 'ResultadoLocal', 'ResultadoVisitante'])\n",
    "\n",
    "# Después de crear el DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        if row['Equipo Local'] == 'Real Madrid':\n",
    "            if int(row['ResultadoLocal']) > int(row['ResultadoVisitante']):\n",
    "                df.loc[index, 'Decision'] = 'Ganado'\n",
    "            elif int(row['ResultadoLocal']) < int(row['ResultadoVisitante']):\n",
    "                df.loc[index, 'Decision'] = 'Perdido'\n",
    "            else:\n",
    "                df.loc[index, 'Decision'] = 'Empatado'\n",
    "        else:\n",
    "            if int(row['ResultadoVisitante']) > int(row['ResultadoLocal']):\n",
    "                df.loc[index, 'Decision'] = 'Ganado'\n",
    "            elif int(row['ResultadoLocal']) > int(row['ResultadoVisitante']):\n",
    "                df.loc[index, 'Decision'] = 'Perdido'\n",
    "            else:\n",
    "                df.loc[index, 'Decision'] = 'Empatado'\n",
    "\n",
    "\n",
    "\n",
    "# Guardar los datos en un archivo Excel\n",
    "    df.to_excel('de la url.xlsx', index=False)\n",
    "    # Aquí puedes procesar los datos obtenidos de la URL\n",
    "else:\n",
    "    print(\"Error al obtener la URL. Código de estado:\", response.status_code)\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODOS LOS PARTIDOS\n",
    "\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Lista de archivos HTML a procesar\n",
    "html_files = [\n",
    "    'html/2014-2015.html',\n",
    "    'html/2015-2016.html',\n",
    "    'html/2016-2017.html',\n",
    "    'html/2017-2018.html',\n",
    "    'html/2018-2019.html',\n",
    "    'html/2019-2020.html',\n",
    "    'html/2020-2021.html',\n",
    "    'html/2021-2022.html',\n",
    "    'html/2022-2023.html'\n",
    "]\n",
    "\n",
    "# Lista para almacenar los datos de todos los archivos\n",
    "data = []\n",
    "\n",
    "for file_name in html_files:\n",
    "    with open(file_name, 'r', encoding='utf-8') as file:\n",
    "        html_content = file.read()\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        matches = soup.find_all('a', class_='match-link', attrs={'data-cy': 'match'})\n",
    "        \n",
    "        for match in matches:\n",
    "                competition_elem = match.find('div', class_='middle-info')\n",
    "                date_elem = match.find('div', class_='date-transform')\n",
    "                home_team_elem = match.find('div', class_='team-name', itemprop='name')\n",
    "                away_team_elems = match.find_all('div', class_='team-name', itemprop='name')\n",
    "                result_elem = match.find('div', class_='marker')\n",
    "                \n",
    "                if date_elem and home_team_elem and len(away_team_elems) > 1 and result_elem:\n",
    "                    result_spans = result_elem.find_all('span')\n",
    "                    if len(result_spans) == 3:  # Ensure there are two result spans and one dash\n",
    "                        result_local = result_spans[1].text.strip()\n",
    "                        result_visitante = result_spans[2].text.strip()\n",
    "                        data.append([\n",
    "                            date_elem.text.strip(),\n",
    "                            competition_elem.text.strip(),\n",
    "                            home_team_elem.text.strip(),\n",
    "                            away_team_elems[1].text.strip(),\n",
    "                            result_elem.text.strip(),\n",
    "                            result_local,\n",
    "                            result_visitante\n",
    "                        ])\n",
    "\n",
    "# Crear un DataFrame con los datos combinados\n",
    "df = pd.DataFrame(data, columns=['Fecha', 'Competición', 'Equipo Local', 'Equipo Visitante','Resultado', 'ResultadoLocal', 'ResultadoVisitante'])\n",
    "\n",
    "# Después de crear el DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    if row['Equipo Local'] == 'Real Madrid':\n",
    "        if int(row['ResultadoLocal']) > int(row['ResultadoVisitante']):\n",
    "            df.loc[index, 'Decision'] = 'Ganado'\n",
    "        elif int(row['ResultadoLocal']) < int(row['ResultadoVisitante']):\n",
    "            df.loc[index, 'Decision'] = 'Perdido'\n",
    "        else:\n",
    "            df.loc[index, 'Decision'] = 'Empatado'\n",
    "    else:\n",
    "        if int(row['ResultadoVisitante']) > int(row['ResultadoLocal']):\n",
    "            df.loc[index, 'Decision'] = 'Ganado'\n",
    "        elif int(row['ResultadoLocal']) > int(row['ResultadoVisitante']):\n",
    "            df.loc[index, 'Decision'] = 'Perdido'\n",
    "        else:\n",
    "            df.loc[index, 'Decision'] = 'Empatado'\n",
    "\n",
    "\n",
    "\n",
    "# Guardar los datos en un archivo Excel\n",
    "df.to_excel('real_madrid_matches_combined.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
